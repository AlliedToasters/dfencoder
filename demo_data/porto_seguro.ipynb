{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ksu36-qh9uON"
   },
   "source": [
    "# Reproducing Porto Seguro Kaggle-Winning Model\n",
    "This notebook has been written specially to run in a Google Colab environment with its hardware limitations. If you have a more powerful system, you should try to modify this notebook to make things run exactly as specified by the Kaggle champion!\n",
    "## Installing Libraries and Downloading Data\n",
    "In Colab, you'll only need to install dfencoder. Dependencies are already installed. <br><br>\n",
    "I've placed the data on github for easy access in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "AfawBLqoSsQW",
    "outputId": "6147d803-afb2-47b5-c75d-dcba763b326e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dfencoder in /usr/local/lib/python3.6/dist-packages (0.0.32)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from dfencoder) (4.28.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from dfencoder) (0.21.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from dfencoder) (1.1.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from dfencoder) (0.24.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dfencoder) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dfencoder) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->dfencoder) (0.13.2)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->dfencoder) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->dfencoder) (2.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->dfencoder) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dfencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "zCbPxFJ8Tkkh",
    "outputId": "c21db427-1bee-4891-85b7-c1790fba3f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-26 23:28:53--  https://github.com/AlliedToasters/public_data/raw/master/test.7z\n",
      "Resolving github.com (github.com)... 192.30.253.113\n",
      "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/AlliedToasters/public_data/master/test.7z [following]\n",
      "--2019-06-26 23:28:53--  https://raw.githubusercontent.com/AlliedToasters/public_data/master/test.7z\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25235310 (24M) [application/octet-stream]\n",
      "Saving to: ‘test.7z’\n",
      "\n",
      "test.7z             100%[===================>]  24.07M   148MB/s    in 0.2s    \n",
      "\n",
      "2019-06-26 23:28:54 (148 MB/s) - ‘test.7z’ saved [25235310/25235310]\n",
      "\n",
      "--2019-06-26 23:28:55--  https://github.com/AlliedToasters/public_data/raw/master/train.7z\n",
      "Resolving github.com (github.com)... 192.30.253.113\n",
      "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/AlliedToasters/public_data/master/train.7z [following]\n",
      "--2019-06-26 23:28:55--  https://raw.githubusercontent.com/AlliedToasters/public_data/master/train.7z\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17022819 (16M) [application/octet-stream]\n",
      "Saving to: ‘train.7z’\n",
      "\n",
      "train.7z            100%[===================>]  16.23M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-06-26 23:28:56 (122 MB/s) - ‘train.7z’ saved [17022819/17022819]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/AlliedToasters/public_data/raw/master/test.7z\n",
    "!wget https://github.com/AlliedToasters/public_data/raw/master/train.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "colab_type": "code",
    "id": "cmKyhQBcTkZy",
    "outputId": "44691c28-9b8f-468e-97a2-95c17df69e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 25235310 bytes (25 MiB)\n",
      "\n",
      "Extracting archive: test.7z\n",
      "--\n",
      "Path = test.7z\n",
      "Type = 7z\n",
      "Physical Size = 25235310\n",
      "Headers Size = 122\n",
      "Method = LZMA2:24\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b  9% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       172006681\n",
      "Compressed: 25235310\n",
      "\n",
      "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 17022819 bytes (17 MiB)\n",
      "\n",
      "Extracting archive: train.7z\n",
      "--\n",
      "Path = train.7z\n",
      "Type = 7z\n",
      "Physical Size = 17022819\n",
      "Headers Size = 122\n",
      "Method = LZMA2:24\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b 17% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       115852544\n",
      "Compressed: 17022819\n"
     ]
    }
   ],
   "source": [
    "#unzip the data\n",
    "!7z x test.7z\n",
    "!7z x train.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vjRzPjZTo_f"
   },
   "outputs": [],
   "source": [
    "#import libraries and load data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import pandas as pd\n",
    "from dfencoder import AutoEncoder\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0jY32Xv-ZMY"
   },
   "source": [
    "# Data Processing\n",
    "If you read the solution carefully, you'll notice a few odd things:\n",
    " - Michael one-hot encoded the categorical variables and then treated them as *numeric* variables. That is, he used MSE as a loss during the DAE representation learning phase.\n",
    " - He left the categorical columns in the dataset and apparently treated them as numeric as well, applying the same scaling he did to other numeric columns (except the one-hot columns).<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlKBwg_o_Deh"
   },
   "source": [
    "\n",
    " These preprocessing steps will reproduce Michael's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XrAPO4VT4tW"
   },
   "outputs": [],
   "source": [
    "#generate lists of column names so we can treat them differently.\n",
    "to_remove = ['id']\n",
    "binary = []\n",
    "cats = []\n",
    "\n",
    "for col in train.columns:\n",
    "    if 'calc' in col:\n",
    "        to_remove.append(col)\n",
    "    elif 'bin' in col:\n",
    "        binary.append(col)\n",
    "    elif 'cat' in col:\n",
    "        cats.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTSaY_I9UtO2"
   },
   "outputs": [],
   "source": [
    "#drop undesired columns.\n",
    "X_train = train.drop(columns=to_remove+['target'])\n",
    "Y_train = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BseY1vE6U8dH"
   },
   "outputs": [],
   "source": [
    "X_test = test.drop(columns=to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TzzdWNgFLj-b"
   },
   "outputs": [],
   "source": [
    "#do our one-hot encoding, naming new columns.\n",
    "for cat in cats:\n",
    "    ohe = pd.get_dummies(X_test[cat])\n",
    "    ohe_columns = [cat + \"_ohe_\" + str(i) for i in ohe.columns]\n",
    "    ohe.columns = ohe_columns\n",
    "    X_test = pd.concat([X_test, ohe], axis=1)\n",
    "\n",
    "    ohe = pd.get_dummies(X_train[cat])\n",
    "    ohe.columns = ohe_columns\n",
    "    X_train = pd.concat([X_train, ohe], axis=1)\n",
    "\n",
    "    binary += ohe_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kbbb2ixMVDRG"
   },
   "outputs": [],
   "source": [
    "#set all column types to numeric\n",
    "for col in X_train.columns:\n",
    "    if col in binary:\n",
    "        X_train[col] = X_train[col].astype(int)\n",
    "        X_test[col] = X_test[col].astype(int)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "colab_type": "code",
    "id": "MQ4u9RDwVa34",
    "outputId": "41b1a964-ad35-4872-99e3-8298b7796ea6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <th>ps_car_06_cat</th>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_ind_02_cat_ohe_-1</th>\n",
       "      <th>ps_ind_02_cat_ohe_1</th>\n",
       "      <th>ps_ind_02_cat_ohe_2</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_car_11_cat_ohe_65</th>\n",
       "      <th>ps_car_11_cat_ohe_66</th>\n",
       "      <th>ps_car_11_cat_ohe_67</th>\n",
       "      <th>ps_car_11_cat_ohe_68</th>\n",
       "      <th>ps_car_11_cat_ohe_69</th>\n",
       "      <th>ps_car_11_cat_ohe_70</th>\n",
       "      <th>ps_car_11_cat_ohe_71</th>\n",
       "      <th>ps_car_11_cat_ohe_72</th>\n",
       "      <th>ps_car_11_cat_ohe_73</th>\n",
       "      <th>ps_car_11_cat_ohe_74</th>\n",
       "      <th>ps_car_11_cat_ohe_75</th>\n",
       "      <th>ps_car_11_cat_ohe_76</th>\n",
       "      <th>ps_car_11_cat_ohe_77</th>\n",
       "      <th>ps_car_11_cat_ohe_78</th>\n",
       "      <th>ps_car_11_cat_ohe_79</th>\n",
       "      <th>ps_car_11_cat_ohe_80</th>\n",
       "      <th>ps_car_11_cat_ohe_81</th>\n",
       "      <th>ps_car_11_cat_ohe_82</th>\n",
       "      <th>ps_car_11_cat_ohe_83</th>\n",
       "      <th>ps_car_11_cat_ohe_84</th>\n",
       "      <th>ps_car_11_cat_ohe_85</th>\n",
       "      <th>ps_car_11_cat_ohe_86</th>\n",
       "      <th>ps_car_11_cat_ohe_87</th>\n",
       "      <th>ps_car_11_cat_ohe_88</th>\n",
       "      <th>ps_car_11_cat_ohe_89</th>\n",
       "      <th>ps_car_11_cat_ohe_90</th>\n",
       "      <th>ps_car_11_cat_ohe_91</th>\n",
       "      <th>ps_car_11_cat_ohe_92</th>\n",
       "      <th>ps_car_11_cat_ohe_93</th>\n",
       "      <th>ps_car_11_cat_ohe_94</th>\n",
       "      <th>ps_car_11_cat_ohe_95</th>\n",
       "      <th>ps_car_11_cat_ohe_96</th>\n",
       "      <th>ps_car_11_cat_ohe_97</th>\n",
       "      <th>ps_car_11_cat_ohe_98</th>\n",
       "      <th>ps_car_11_cat_ohe_99</th>\n",
       "      <th>ps_car_11_cat_ohe_100</th>\n",
       "      <th>ps_car_11_cat_ohe_101</th>\n",
       "      <th>ps_car_11_cat_ohe_102</th>\n",
       "      <th>ps_car_11_cat_ohe_103</th>\n",
       "      <th>ps_car_11_cat_ohe_104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.718070</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.883679</td>\n",
       "      <td>0.370810</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.618817</td>\n",
       "      <td>0.388716</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.641586</td>\n",
       "      <td>0.347275</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.580948</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.542949</td>\n",
       "      <td>0.294958</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.840759</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>0.316070</td>\n",
       "      <td>0.565832</td>\n",
       "      <td>0.365103</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ps_ind_01  ps_ind_02_cat  ...  ps_car_11_cat_ohe_103  ps_car_11_cat_ohe_104\n",
       "0          2              2  ...                      0                      0\n",
       "1          1              1  ...                      0                      0\n",
       "2          5              4  ...                      0                      0\n",
       "3          0              1  ...                      0                      1\n",
       "4          0              2  ...                      0                      0\n",
       "\n",
       "[5 rows x 221 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#our dataframe should have 221 columns, all numeric.\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MyFhpSxg_kgl"
   },
   "outputs": [],
   "source": [
    "#dfencoder allows us to specify scaling behavior per-feature;\n",
    "#this dictionary will specify not to scale one-hot encoded features.\n",
    "scaler_spec = {ft:None for ft in binary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8aKqEHS_tav"
   },
   "source": [
    "# Hardware Limitations of Colab\n",
    "Unfortunately, the Google Colab environment does not have enough memory to hold both the train and test sets as expanded numeric dataframes.  Michael's system has 32 GB of memory, while we only have < 13 GB here.<br><br>\n",
    "For this reason, we'll only train our DAE on the train set, reserving a small sample of the test set for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XOuW3pDMMT4"
   },
   "outputs": [],
   "source": [
    "#validation sample\n",
    "X_val = X_test.sample(frac=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9maeAKfpRXwd",
    "outputId": "408d182c-ca82-46bc-85a5-acabe6259f20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the encoded test set for later\n",
    "X_test.to_hdf('X_test.h5', key='stage', mode='w')\n",
    "\n",
    "\n",
    "\n",
    "#delete references to memory-consuming data\n",
    "import gc\n",
    "\n",
    "del train\n",
    "del test\n",
    "del X_test\n",
    "\n",
    "#remove objects from memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHDN1ZuSCnps"
   },
   "source": [
    "# Building the DAE\n",
    "We can follow Michael's description of his model to the letter. From the write-up:<br>\n",
    "![](https://raw.githubusercontent.com/AlliedToasters/dfencoder/master/demo_data/dae_arch.png?raw=true)<br><br>\n",
    "In dfencoder, this translates to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVwgWyauVdSq"
   },
   "outputs": [],
   "source": [
    "encoder = AutoEncoder(\n",
    "    #input/output layers are implicit, so just these three...\n",
    "    encoder_layers=[1500, 1500, 1500],\n",
    "    decoder_layers=[],\n",
    "    lr=2.8e-3,\n",
    "    batch_size=128,\n",
    "    activation='relu',\n",
    "    lr_decay=.995,\n",
    "    #here's your swap noise\n",
    "    swap_p=.2,\n",
    "    scaler=scaler_spec,\n",
    "    optimizer='sgd',\n",
    "    verbose=False,\n",
    "    logger='ipynb'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_5XO4knDX_u"
   },
   "source": [
    "# Fitting\n",
    "Running 1000 epochs as specified takes a long time. It took Michael 5 hours, and this appears to take longer. Looks like we need to optimize the library. To be fair, Michael did everything in a compiled program in C++ ; in python we're carrying around a bunch of extra overhead. But, if you have the hardware and the patience, you can do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "colab_type": "code",
    "id": "Po_9jSx6WptW",
    "outputId": "26eb046f-9d6d-4631-f312-ed5c0837785c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAESCAYAAAAFYll6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIUIm4SGEECJkEh5CCCFCJuEhhBAiZP8fyWSkG1dIaZMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder.fit(X_train, val=X_val, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHzT-t4EDzH6"
   },
   "source": [
    "# Classifier Model\n",
    "Creating the classifier model... From the write-up:<br>\n",
    "![](https://github.com/AlliedToasters/dfencoder/raw/master/demo_data/nn_arch.png?raw=true)<br><br>\n",
    "We can just whip this model up using pytorch (some ambiguity about \"regL2\" vs weight decay, possibly a factor of 2 error?  See [this article](https://bbabenko.github.io/weight-decay/). I would double the parameter but weight decay of .1 seems really high...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWgv92lueY_h"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ClassifierModel(torch.nn.Module):\n",
    "  \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ClassifierModel, self).__init__(*args, **kwargs)\n",
    "        self.input_dropout = torch.nn.Dropout(.1)\n",
    "        self.input_layer = torch.nn.Linear(4500, 1000)\n",
    "        self.dropout = torch.nn.Dropout(.5)\n",
    "        self.dense1 = torch.nn.Linear(1000, 1000)\n",
    "        self.dense2 = torch.nn.Linear(1000, 1000)\n",
    "        self.output = torch.nn.Linear(1000, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_dropout(x)\n",
    "\n",
    "        x = self.input_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.dense2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.output(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "classifier = ClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c1uJ5EX8GNIm"
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(\n",
    "    classifier.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=.05,\n",
    "    \n",
    ")\n",
    "\n",
    "decay = torch.optim.lr_scheduler.ExponentialLR(optim, .995)\n",
    "\n",
    "loss = torch.nn.modules.loss.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jm0c55Z8LSlv"
   },
   "outputs": [],
   "source": [
    "classifier = classifier.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftziyukYEHcf"
   },
   "source": [
    "Saving memory has been a headache in colab... These calls free up RAM and GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JxREdz-ghbOt",
    "outputId": "6624ea70-67f1-4b87-fda4-100a38428c2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22543"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsJ-_aTgAAg3"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46zmuXp7EQE9"
   },
   "source": [
    "# Training\n",
    "To speed things up, we can compute the deep stack features in big batches in advance. However, with our lack of memory, we can't do this all at once. To work around this, we'll split the data into thirds, computing latent features in \"megabatches\" during training. This seems to get the job done pretty quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Jy_Xa34nfgAY",
    "outputId": "2d044d03-c670-4436-9d19-ba2ca7b1fac9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4651/4651 [00:21<00:00, 212.16it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 212.89it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 393.97it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 214.13it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 213.34it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 214.01it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 212.78it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 212.96it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 214.34it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 213.99it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 213.95it/s]\n",
      "100%|██████████| 4651/4651 [00:21<00:00, 214.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def do_step(classifier, optim, z, target, loss):\n",
    "    pred = classifier(z)\n",
    "    target = torch.tensor(target).float().reshape(-1, 1).to(\"cuda:0\")\n",
    "    loss_ = loss(pred, target)\n",
    "    amnt = loss_.item()\n",
    "    loss_.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    return amnt\n",
    "  \n",
    "batch_size = 128\n",
    "n_updates = (len(X_train)//batch_size) + 1\n",
    "\n",
    "n_megabatches = 3\n",
    "n_epochs = 150\n",
    "\n",
    "n_rows = len(X_train)\n",
    "\n",
    "res = n_rows/n_megabatches\n",
    "batches_per_megabatch = (res // batch_size) + 1\n",
    "megabatch_size = batches_per_megabatch * batch_size\n",
    "final_batch_size = n_rows - (n_megabatches - 1) * megabatch_size\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    with tqdm.tqdm(total=n_updates) as bar:\n",
    "        for j in range(n_megabatches):\n",
    "            mega_start = int((j) * megabatch_size)\n",
    "            mega_stop = int((j+1) * megabatch_size)\n",
    "            slc = X_train.iloc[mega_start:mega_stop]\n",
    "            z = encoder.get_deep_stack_features(slc)\n",
    "            target_slc = Y_train.iloc[mega_start:mega_stop].values\n",
    "            if j == (n_megabatches-1):\n",
    "        steps = final_batch_size/batch_size\n",
    "        if final_batch_size % batch_size != 0:\n",
    "            steps += 1\n",
    "        else:\n",
    "            steps = batches_per_megabatch\n",
    "        steps = int(steps)\n",
    "        for i in range(steps):\n",
    "            step = i\n",
    "            start = int((step) * batch_size)\n",
    "            stop = int((step+1) * batch_size)\n",
    "            in_ = z[start:stop]\n",
    "            target = target_slc[start:stop]\n",
    "            do_step(classifier, optim, in_, target, loss)\n",
    "            bar.update(1)\n",
    "    decay.step()\n",
    "    del z\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJ5yj4ONGfvQ"
   },
   "source": [
    "# Inference\n",
    "Now we can get our predictions on the test set.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zL2ltZ-JLEnE"
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_hdf('X_test.h5')\n",
    "test = pd.read_csv('test.csv')\n",
    "ids = test['id'].values\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXmaHl8BOJKz"
   },
   "outputs": [],
   "source": [
    "def do_inference(encoder, classifier, data):\n",
    "    z = torch.tensor(encoder.get_deep_stack_features(data)).to(\"cuda:0\")\n",
    "    output = classifier(z)\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "HVC93zi6OvEJ",
    "outputId": "40d13523-fa1a-4d7c-dfbb-6c976f3a9445"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 436/436 [01:41<00:00,  4.37it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "eval_batch_size = 2048\n",
    "n_batches = (len(X_test)//eval_batch_size) + 1\n",
    "#n_batches = 10\n",
    "\n",
    "out = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm.trange(n_batches):\n",
    "        start = i * eval_batch_size\n",
    "        stop = (i+1) * eval_batch_size\n",
    "        slc = X_test.iloc[start:stop]\n",
    "        res = do_inference(encoder, classifier, slc)\n",
    "        out.append(res.reshape(-1))\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttK77knnT3jw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "result = np.concatenate([vec.cpu().numpy() for vec in out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vq33ahnLGmNI"
   },
   "source": [
    "# Formatting Data for Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41NAcWwrVcIf"
   },
   "outputs": [],
   "source": [
    "to_submit = pd.DataFrame()\n",
    "to_submit['id'] = ids\n",
    "to_submit['target'] = result\n",
    "\n",
    "to_submit.to_csv('submission.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOTpOT_sGqH5"
   },
   "source": [
    "# Submitting Directly to Kaggle with Kaggle API\n",
    "Just insert your username and key into the corresponding fields in the next cell and this will submit for you.<br>\n",
    "When I run this in Colab, I get an error message, but the dataset is received by Kaggle anyway! ¯\\\\_(ツ)_/¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZFfA7ZrWwVY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"<YOUR USERNAME>\"\n",
    "os.environ['KAGGLE_KEY'] = \"<YOUR API KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "PgnPFpy_XCwY",
    "outputId": "4e44c517-a4a4-4237-ce1f-1cf91f771dba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% 16.1M/16.1M [00:03<00:00, 5.21MB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/cli.py\", line 64, in main\n",
      "    print(out, end='')\n",
      "UnicodeEncodeError: 'latin-1' codec can't encode character u'\\u2019' in position 38: ordinal not in range(256)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c porto-seguro-safe-driver-prediction -f submission.csv -m test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "soaaKHgBHIWQ"
   },
   "source": [
    "Run this code, modify it, and see if you can get to the top 1% on the leaderboard! Let me know if I missed anything or did anything wrong - so far I haven't been able to get a high score but I probably overlooked something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-M4r8wwHILy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anGI0BJsnrCi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "porto_seguro.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
